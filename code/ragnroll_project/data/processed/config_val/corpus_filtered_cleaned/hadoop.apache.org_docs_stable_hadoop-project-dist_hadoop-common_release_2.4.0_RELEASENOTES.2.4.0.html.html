<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 3.4.1 &#x2013; Apache Hadoop  2.4.0 Release Notes</title>
    
    
        <meta name="Date-Revision-yyyymmdd" content="20241009" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                     <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://gitbox.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                   &nbsp;| Last Published: 2024-10-09
              &nbsp;| Version: 3.4.1
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Common</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  
                  
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  
                  
                  
                  
                  
          </ul>
                       <h5>YARN Service</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  
                  
                  
                  
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  
                  
                  
                  
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        
<h1>Apache Hadoop  2.4.0 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, important issues, features, and major improvements.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5790">HDFS-5790</a> | <i>Major</i> | <b>LeaseManager.findPath is very slow when many leases need recovery</b></li>
</ul>
<p>Committed to branch-2 and trunk.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10295">HADOOP-10295</a> | <i>Major</i> | <b>Allow distcp to automatically identify the checksum type of source files and use it for the target</b></li>
</ul>
<p>Add option for distcp to preserve the checksum type of the source files. Users can use &#x201c;-pc&#x201d; as distcp command option to preserve the checksum type.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5804">HDFS-5804</a> | <i>Major</i> | <b>HDFS NFS Gateway fails to mount and proxy when using Kerberos</b></li>
</ul>
<p>Fixes NFS on Kerberized cluster.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5698">HDFS-5698</a> | <i>Major</i> | <b>Use protobuf to serialize / deserialize FSImage</b></li>
</ul>
<p>Use protobuf to serialize/deserialize the FSImage.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-4370">HDFS-4370</a> | <i>Major</i> | <b>Fix typo Blanacer in DataNode</b></li>
</ul>
<p>I just committed this. Thank you Chu.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5776">HDFS-5776</a> | <i>Major</i> | <b>Support &#x2018;hedged&#x2019; reads in DFSClient</b></li>
</ul>
<p>If a read from a block is slow, start up another parallel, &#x2018;hedged&#x2019; read against a different block replica.  We then take the result of which ever read returns first (the outstanding read is cancelled).  This &#x2018;hedged&#x2019; read feature will help rein in the outliers, the odd read that takes a long time because it hit a bad patch on the disc, etc.</p>
<p>This feature is off by default.  To enable this feature, set &lt;code&gt;dfs.client.hedged.read.threadpool.size&lt;/code&gt; to a positive number.  The threadpool size is how many threads to dedicate to the running of these &#x2018;hedged&#x2019;, concurrent reads in your client.</p>
<p>Then set &lt;code&gt;dfs.client.hedged.read.threshold.millis&lt;/code&gt; to the number of milliseconds to wait before starting up a &#x2018;hedged&#x2019; read.  For example, if you set this property to 10, then if a read has not returned within 10 milliseconds, we will start up a new read against a different block replica.</p>
<p>This feature emits new metrics:</p>
<ul>

<li>hedgedReadOps</li>
<li>hedgeReadOpsWin &#x2013; how many times the hedged read &#x2018;beat&#x2019; the original read</li>
<li>hedgedReadOpsInCurThread &#x2013; how many times we went to do a hedged read but we had to run it in the current thread because dfs.client.hedged.read.threadpool.size was at a maximum.</li>
</ul><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-8691">HADOOP-8691</a> | <i>Minor</i> | <b>FsShell can print &#x201c;Found xxx items&#x201d; unnecessarily often</b></li>
</ul>
<p>The `ls` command only prints &#x201c;Found foo items&#x201d; once when listing the directories recursively.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5321">HDFS-5321</a> | <i>Major</i> | <b>Clean up the HTTP-related configuration in HDFS</b></li>
</ul>
<p>dfs.http.port and dfs.https.port are removed. Filesystem clients, such as WebHdfsFileSystem, now have fixed instead of configurable default ports (i.e., 50070 for http and 50470 for https).</p>
<p>Users can explicitly specify the port in the URI to access the file system which runs on non-default ports.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10211">HADOOP-10211</a> | <i>Major</i> | <b>Enable RPC protocol to negotiate SASL-QOP values between clients and servers</b></li>
</ul>
<p>The hadoop.rpc.protection configuration property previously supported specifying a single value: one of authentication, integrity or privacy.  An unrecognized value was silently assumed to mean authentication.  This configuration property now accepts a comma-separated list of any of the 3 values, and unrecognized values are rejected with an error. Existing configurations containing an invalid value must be corrected. If the property is empty or not specified, authentication is assumed.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-6055">HDFS-6055</a> | <i>Major</i> | <b>Change default configuration to limit file name length in HDFS</b></li>
</ul>
<p>The default configuration of HDFS now sets dfs.namenode.fs-limits.max-component-length to 255 for improved interoperability with other file system implementations.  This limits each component of a file system path to a maximum of 255 bytes in UTF-8 encoding.  Attempts to create new files that violate this rule will fail with an error.  Existing files that violate the rule are not effected.  Previously, dfs.namenode.fs-limits.max-component-length was set to 0 (ignored).  If necessary, it is possible to set the value back to 0 in the cluster&#x2019;s configuration to restore the old behavior.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-6102">HDFS-6102</a> | <i>Blocker</i> | <b>Lower the default maximum items per directory to fix PB fsimage loading</b></li>
</ul>
<p><b>WARNING: No release note provided for this change.</b></p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10221">HADOOP-10221</a> | <i>Major</i> | <b>Add a plugin to specify SaslProperties for RPC protocol based on connection properties</b></li>
</ul>
<p>SaslPropertiesResolver  or its subclass is used to resolve the QOP used for a connection. The subclass can be specified via &#x201c;hadoop.security.saslproperties.resolver.class&#x201d; configuration property. If not specified, the full set of values specified in hadoop.rpc.protection is used while determining the QOP used for the  connection. If a class is specified, then the QOP values returned by the class will be used while determining the QOP used for the connection.</p>
<p>Note that this change, effectively removes SaslRpcServer.SASL_PROPS which was a public field. Any use of this variable  should be replaced with the following code: SaslPropertiesResolver saslPropsResolver = SaslPropertiesResolver.getInstance(conf); Map&lt;String, String&gt; sasl_props = saslPropsResolver.getDefaultProperties();</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-4685">HDFS-4685</a> | <i>Major</i> | <b>Implementation of ACLs in HDFS</b></li>
</ul>
<p>HDFS now supports ACLs (Access Control Lists).  ACLs can specify fine-grained file permissions for specific named users or named groups.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5138">HDFS-5138</a> | <i>Blocker</i> | <b>Support HDFS upgrade in HA</b></li>
</ul>
<p><b>WARNING: No release note provided for this change.</b></p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-5036">MAPREDUCE-5036</a> | <i>Major</i> | <b>Default shuffle handler port should not be 8080</b></li>
</ul>
<p><b>WARNING: No release note provided for this change.</b></p>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2008-2024
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
