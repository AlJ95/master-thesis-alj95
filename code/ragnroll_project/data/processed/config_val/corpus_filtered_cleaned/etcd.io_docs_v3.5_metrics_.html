<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Metrics | etcd</title>
<meta name=description content="Metrics for real-time monitoring and debugging"><meta property="og:url" content="https://etcd.io/docs/v3.5/metrics/"><meta property="og:site_name" content="etcd"><meta property="og:title" content="Metrics"><meta property="og:description" content="Metrics for real-time monitoring and debugging"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2024-03-23T00:51:46+01:00"><meta itemprop=name content="Metrics"><meta itemprop=description content="Metrics for real-time monitoring and debugging"><meta itemprop=dateModified content="2024-03-23T00:51:46+01:00"><meta itemprop=wordCount content="974"><meta name=twitter:card content="summary"><meta name=twitter:title content="Metrics"><meta name=twitter:description content="Metrics for real-time monitoring and debugging"></head><body class=td-page><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><h1>Metrics</h1><div class=lead>Metrics for real-time monitoring and debugging</div><p>etcd uses <a href=https://prometheus.io/ target=_blank rel=noopener>Prometheus</a> for metrics reporting. The metrics can be used for real-time monitoring and debugging. etcd does not persist its metrics; if a member restarts, the metrics will be reset.</p><p>The simplest way to see the available metrics is to cURL the metrics endpoint <code>/metrics</code>. The format is described <a href=http://prometheus.io/docs/instrumenting/exposition_formats/ target=_blank rel=noopener>here</a>.</p><p>Follow the <a href=https://prometheus.io/docs/introduction/getting_started/ target=_blank rel=noopener>Prometheus getting started doc</a> to spin up a Prometheus server to collect etcd metrics.</p><p>The naming of metrics follows the suggested <a href=https://prometheus.io/docs/practices/naming/ target=_blank rel=noopener>Prometheus best practices</a>. A metric name has an <code>etcd</code> or <code>etcd_debugging</code> prefix as its namespace and a subsystem prefix (for example <code>wal</code> and <code>etcdserver</code>).</p><h2 id=etcd-namespace-metrics>etcd namespace metrics</h2><p>The metrics under the <code>etcd</code> prefix are for monitoring and alerting. They are stable high level metrics. If there is any change of these metrics, it will be included in release notes.</p><p>Metrics that are etcd2 related are documented in the <a href=/docs/v2.3/metrics/#http-requests>v2 metrics guide</a>.</p><h3 id=server>Server</h3><p>These metrics describe the status of the etcd server. In order to detect outages or problems for troubleshooting, the server metrics of every production etcd cluster should be closely monitored.</p><p>All these metrics are prefixed with <code>etcd_server_</code></p><table><thead><tr><th>Name</th><th>Description</th><th>Type</th></tr></thead><tbody><tr><td>has_leader</td><td>Whether or not a leader exists. 1 is existence, 0 is not.</td><td>Gauge</td></tr><tr><td>leader_changes_seen_total</td><td>The number of leader changes seen.</td><td>Counter</td></tr><tr><td>proposals_committed_total</td><td>The total number of consensus proposals committed.</td><td>Gauge</td></tr><tr><td>proposals_applied_total</td><td>The total number of consensus proposals applied.</td><td>Gauge</td></tr><tr><td>proposals_pending</td><td>The current number of pending proposals.</td><td>Gauge</td></tr><tr><td>proposals_failed_total</td><td>The total number of failed proposals seen.</td><td>Counter</td></tr></tbody></table><p><code>has_leader</code> indicates whether the member has a leader. If a member does not have a leader, it is
totally unavailable. If all the members in the cluster do not have any leader, the entire cluster
is totally unavailable.</p><p><code>leader_changes_seen_total</code> counts the number of leader changes the member has seen since its start. Rapid leadership changes impact the performance of etcd significantly. It also signals that the leader is unstable, perhaps due to network connectivity issues or excessive load hitting the etcd cluster.</p><p><code>proposals_committed_total</code> records the total number of consensus proposals committed. This gauge should increase over time if the cluster is healthy. Several healthy members of an etcd cluster may have different total committed proposals at once. This discrepancy may be due to recovering from peers after starting, lagging behind the leader, or being the leader and therefore having the most commits. It is important to monitor this metric across all the members in the cluster; a consistently large lag between a single member and its leader indicates that member is slow or unhealthy.</p><p><code>proposals_applied_total</code> records the total number of consensus proposals applied. The etcd server applies every committed proposal asynchronously. The difference between <code>proposals_committed_total</code> and <code>proposals_applied_total</code> should usually be small (within a few thousands even under high load). If the difference between them continues to rise, it indicates that the etcd server is overloaded. This might happen when applying expensive queries like heavy range queries or large txn operations.</p><p><code>proposals_pending</code> indicates how many proposals are queued to commit. Rising pending proposals suggests there is a high client load or the member cannot commit proposals.</p><p><code>proposals_failed_total</code> are normally related to two issues: temporary failures related to a leader election or longer downtime caused by a loss of quorum in the cluster.</p><h3 id=disk>Disk</h3><p>These metrics describe the status of the disk operations.</p><p>All these metrics are prefixed with <code>etcd_disk_</code>.</p><table><thead><tr><th>Name</th><th>Description</th><th>Type</th></tr></thead><tbody><tr><td>wal_fsync_duration_seconds</td><td>The latency distributions of fsync called by wal</td><td>Histogram</td></tr><tr><td>backend_commit_duration_seconds</td><td>The latency distributions of commit called by backend.</td><td>Histogram</td></tr></tbody></table><p>A <code>wal_fsync</code> is called when etcd persists its log entries to disk before applying them.</p><p>A <code>backend_commit</code> is called when etcd commits an incremental snapshot of its most recent changes to disk.</p><p>High disk operation latencies (<code>wal_fsync_duration_seconds</code> or <code>backend_commit_duration_seconds</code>) often indicate disk issues. It may cause high request latency or make the cluster unstable.</p><h3 id=network>Network</h3><p>These metrics describe the status of the network.</p><p>All these metrics are prefixed with <code>etcd_network_</code></p><table><thead><tr><th>Name</th><th>Description</th><th>Type</th></tr></thead><tbody><tr><td>peer_sent_bytes_total</td><td>The total number of bytes sent to the peer with ID <code>To</code>.</td><td>Counter(To)</td></tr><tr><td>peer_received_bytes_total</td><td>The total number of bytes received from the peer with ID <code>From</code>.</td><td>Counter(From)</td></tr><tr><td>peer_sent_failures_total</td><td>The total number of send failures from the peer with ID <code>To</code>.</td><td>Counter(To)</td></tr><tr><td>peer_received_failures_total</td><td>The total number of receive failures from the peer with ID <code>From</code>.</td><td>Counter(From)</td></tr><tr><td>peer_round_trip_time_seconds</td><td>Round-Trip-Time histogram between peers.</td><td>Histogram(To)</td></tr><tr><td>client_grpc_sent_bytes_total</td><td>The total number of bytes sent to grpc clients.</td><td>Counter</td></tr><tr><td>client_grpc_received_bytes_total</td><td>The total number of bytes received to grpc clients.</td><td>Counter</td></tr></tbody></table><p><code>peer_sent_bytes_total</code> counts the total number of bytes sent to a specific peer. Usually the leader member sends more data than other members since it is responsible for transmitting replicated data.</p><p><code>peer_received_bytes_total</code> counts the total number of bytes received from a specific peer. Usually follower members receive data only from the leader member.</p><h3 id=grpc-requests>gRPC requests</h3><p>These metrics are exposed via <a href=https://github.com/grpc-ecosystem/go-grpc-prometheus target=_blank rel=noopener>go-grpc-prometheus</a>.</p><h2 id=etcd_debugging-namespace-metrics>etcd_debugging namespace metrics</h2><p>The metrics under the <code>etcd_debugging</code> prefix are for debugging. They are very implementation dependent and volatile. They might be changed or removed without any warning in new etcd releases. Some of the metrics might be moved to the <code>etcd</code> prefix when they become more stable.</p><h3 id=snapshot>Snapshot</h3><table><thead><tr><th>Name</th><th>Description</th><th>Type</th></tr></thead><tbody><tr><td>snapshot_save_total_duration_seconds</td><td>The total latency distributions of save called by snapshot</td><td>Histogram</td></tr></tbody></table><p>Abnormally high snapshot duration (<code>snapshot_save_total_duration_seconds</code>) indicates disk issues and might cause the cluster to be unstable.</p><h2 id=prometheus-supplied-metrics>Prometheus supplied metrics</h2><p>The Prometheus client library provides a number of metrics under the <code>go</code> and <code>process</code> namespaces. There are a few that are particularly interesting.</p><table><thead><tr><th>Name</th><th>Description</th><th>Type</th></tr></thead><tbody><tr><td>process_open_fds</td><td>Number of open file descriptors.</td><td>Gauge</td></tr><tr><td>process_max_fds</td><td>Maximum number of open file descriptors.</td><td>Gauge</td></tr></tbody></table><p><strong>Note</strong>: The process metrics, such as <code>process_open_fds</code> and <code>process_max_fds</code>, are not supported on Darwin (macOS) systems at this time.</p><p>Heavy file descriptor (<code>process_open_fds</code>) usage (i.e., near the process&rsquo;s file descriptor limit, <code>process_max_fds</code>) indicates a potential file descriptor exhaustion issue. If the file descriptors are exhausted, etcd may panic because it cannot create new WAL files.</p><h2 id=generated-list-of-metrics>Generated list of metrics</h2><table><tr><td><a href=etcd-metrics-latest.txt>latest</a></td></table><div class=d-print-none><h2 class=feedback--title>Feedback</h2><p class=feedback--question>Was this page helpful?</p><button class="btn btn-primary mb-4 feedback--answer feedback--answer-yes">Yes</button>
<button class="btn btn-primary mb-4 feedback--answer feedback--answer-no">No</button><p class="feedback--response feedback--response-yes">Glad to hear it! Please <a href=https://github.com/etcd-io/website/issues/new>tell us how we can improve</a>.</p><p class="feedback--response feedback--response-no">Sorry to hear that. Please <a href=https://github.com/etcd-io/website/issues/new>tell us how we can improve</a>.</p></div><br><div class=td-page-meta__lastmod>Last modified March 23, 2024: <a href=https://github.com/etcd-io/website/commit/8adf69fd8bd55991b735bcea5d5edc88abc4b7c9>website: add note on lack of process metrics support for Darwin (8adf69f)</a></div></div></main></div></div></div></body></html>