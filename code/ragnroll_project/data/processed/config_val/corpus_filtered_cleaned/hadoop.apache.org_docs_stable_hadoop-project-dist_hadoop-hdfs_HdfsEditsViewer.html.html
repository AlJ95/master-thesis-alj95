<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 3.4.1 &#x2013; Offline Edits Viewer Guide</title>
    
    
        <meta name="Date-Revision-yyyymmdd" content="20241009" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                     <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://gitbox.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                   &nbsp;| Last Published: 2024-10-09
              &nbsp;| Version: 3.4.1
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Common</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  
                  
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  
                  
                  
                  
                  
          </ul>
                       <h5>YARN Service</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  
                  
                  
                  
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  
                  
                  
                  
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        
<h1>Offline Edits Viewer Guide</h1>
<ul>



</ul></li>

</ul>
<section>
<h2><a name="Overview"></a>Overview</h2>
<p>Offline Edits Viewer is a tool to parse the Edits log file. The current processors are mostly useful for conversion between different formats, including XML which is human readable and easier to edit than native binary format.</p>
<p>The tool can parse the edits formats -18 (roughly Hadoop 0.19) and later. The tool operates on files only, it does not need Hadoop cluster to be running.</p>
<p>Input formats supported:</p>
<ol style="list-style-type: decimal">

<li><b>binary</b>: native binary format that Hadoop uses internally</li>
<li><b>xml</b>: XML format, as produced by xml processor, used if filename has <code>.xml</code> (case insensitive) extension</li>
</ol>
<p>Note: XML/Binary format input file is not allowed to be processed by the same type processor.</p>
<p>The Offline Edits Viewer provides several output processors (unless stated otherwise the output of the processor can be converted back to original edits file):</p>
<ol style="list-style-type: decimal">

<li><b>binary</b>: native binary format that Hadoop uses internally</li>
<li><b>xml</b>: XML format</li>
<li><b>stats</b>: prints out statistics, this cannot be converted back to Edits file</li>
</ol></section><section>
<h2><a name="Usage"></a>Usage</h2><section>
<h3><a name="XML_Processor"></a>XML Processor</h3>
<p>XML processor can create an XML file that contains the edits log information. Users can specify input and output file via -i and -o command-line.</p>

<div class="source">
<div class="source">
<pre>   bash$ bin/hdfs oev -p xml -i edits -o edits.xml
</pre></div></div>

<p>XML processor is the default processor in Offline Edits Viewer, users can also use the following command:</p>

<div class="source">
<div class="source">
<pre>   bash$ bin/hdfs oev -i edits -o edits.xml
</pre></div></div>

<p>This would result in the following output:</p>

<div class="source">
<div class="source">
<pre>   &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
   &lt;EDITS&gt;
     &lt;EDITS_VERSION&gt;-64&lt;/EDITS_VERSION&gt;
     &lt;RECORD&gt;
       &lt;OPCODE&gt;OP_START_LOG_SEGMENT&lt;/OPCODE&gt;
       &lt;DATA&gt;
         &lt;TXID&gt;1&lt;/TXID&gt;
       &lt;/DATA&gt;
     &lt;/RECORD&gt;
     &lt;RECORD&gt;
       &lt;OPCODE&gt;OP_UPDATE_MASTER_KEY&lt;/OPCODE&gt;
       &lt;DATA&gt;
         &lt;TXID&gt;2&lt;/TXID&gt;
         &lt;DELEGATION_KEY&gt;
           &lt;KEY_ID&gt;1&lt;/KEY_ID&gt;
           &lt;EXPIRY_DATE&gt;1487921580728&lt;/EXPIRY_DATE&gt;
           &lt;KEY&gt;2e127ca41c7de215&lt;/KEY&gt;
         &lt;/DELEGATION_KEY&gt;
       &lt;/DATA&gt;
     &lt;/RECORD&gt;
     &lt;RECORD&gt;
   ...remaining output omitted...
</pre></div></div>
</section><section>
<h3><a name="Binary_Processor"></a>Binary Processor</h3>
<p>Binary processor is the opposite of the XML processor. Users can specify input XML file and output file via -i and -o command-line.</p>

<div class="source">
<div class="source">
<pre>   bash$ bin/hdfs oev -p binary -i edits.xml -o edits
</pre></div></div>

<p>This will reconstruct an edits log file from an XML file.</p></section><section>
<h3><a name="Stats_Processor"></a>Stats Processor</h3>
<p>Stats processor is used to aggregate counts of op codes contained in the edits log file. Users can specify this processor by -p option.</p>

<div class="source">
<div class="source">
<pre>   bash$ bin/hdfs oev -p stats -i edits -o edits.stats
</pre></div></div>

<p>The output result of this processor should be like the following output:</p>

<div class="source">
<div class="source">
<pre>   VERSION                             : -64
   OP_ADD                         (  0): 8
   OP_RENAME_OLD                  (  1): 1
   OP_DELETE                      (  2): 1
   OP_MKDIR                       (  3): 1
   OP_SET_REPLICATION             (  4): 1
   OP_DATANODE_ADD                (  5): 0
   OP_DATANODE_REMOVE             (  6): 0
   OP_SET_PERMISSIONS             (  7): 1
   OP_SET_OWNER                   (  8): 1
   OP_CLOSE                       (  9): 9
   OP_SET_GENSTAMP_V1             ( 10): 0
   ...some output omitted...
   OP_APPEND                      ( 47): 1
   OP_SET_QUOTA_BY_STORAGETYPE    ( 48): 1
   OP_ADD_ERASURE_CODING_POLICY   ( 49): 0
   OP_ENABLE_ERASURE_CODING_POLICY  ( 50): 1
   OP_DISABLE_ERASURE_CODING_POLICY ( 51): 0
   OP_REMOVE_ERASURE_CODING_POLICY  ( 52): 0
   OP_INVALID                     ( -1): 0
</pre></div></div>

<p>The output is formatted as a colon separated two column table: OpCode and OpCodeCount. Each OpCode corresponding to the specific operation(s) in NameNode.</p></section></section><section>
<h2><a name="Options"></a>Options</h2>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th align="left"> Flag </th>
<th align="left"> Description </th></tr>
</thead><tbody>

<tr class="b">
<td align="left"> [<code>-i</code> ; <code>--inputFile</code>] <i>input file</i> </td>
<td align="left"> Specify the input edits log file to process. Xml (case insensitive) extension means XML format otherwise binary format is assumed. Required. </td></tr>
<tr class="a">
<td align="left"> [<code>-o</code> ; <code>--outputFile</code>] <i>output file</i> </td>
<td align="left"> Specify the output filename, if the specified output processor generates one. If the specified file already exists, it is silently overwritten. Required. </td></tr>
<tr class="b">
<td align="left"> [<code>-p</code> ; <code>--processor</code>] <i>processor</i> </td>
<td align="left"> Specify the image processor to apply against the image file. Currently valid options are <code>binary</code>, <code>xml</code> (default) and <code>stats</code>. </td></tr>
<tr class="a">
<td align="left"> [<code>-v</code> ; <code>--verbose</code>] </td>
<td align="left"> Print the input and output filenames and pipe output of processor to console as well as specified file. On extremely large files, this may increase processing time by an order of magnitude. </td></tr>
<tr class="b">
<td align="left"> [<code>-f</code> ; <code>--fix-txids</code>] </td>
<td align="left"> Renumber the transaction IDs in the input, so that there are no gaps or invalid transaction IDs. </td></tr>
<tr class="a">
<td align="left"> [<code>-r</code> ; <code>--recover</code>] </td>
<td align="left"> When reading binary edit logs, use recovery mode. This will give you the chance to skip corrupt parts of the edit log. </td></tr>
<tr class="b">
<td align="left"> [<code>-h</code> ; <code>--help</code>] </td>
<td align="left"> Display the tool usage and help information and exit. </td></tr>
</tbody>
</table></section><section>
<h2><a name="Case_study:_Hadoop_cluster_recovery"></a>Case study: Hadoop cluster recovery</h2>
<p>In case there is some problem with hadoop cluster and the edits file is corrupted it is possible to save at least part of the edits file that is correct. This can be done by converting the binary edits to XML, edit it manually and then convert it back to binary. The most common problem is that the edits file is missing the closing record (record that has opCode -1). This should be recognized by the tool and the XML format should be properly closed.</p>
<p>If there is no closing record in the XML file you can add one after last correct record. Anything after the record with opCode -1 is ignored.</p>
<p>Example of a closing record (with opCode -1):</p>

<div class="source">
<div class="source">
<pre>  &lt;RECORD&gt;
    &lt;OPCODE&gt;-1&lt;/OPCODE&gt;
    &lt;DATA&gt;
    &lt;/DATA&gt;
  &lt;/RECORD&gt;
</pre></div></div></section>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2008-2024
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
