<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 3.4.1 &#x2013; Apache Hadoop  2.3.0 Release Notes</title>
    
    
        <meta name="Date-Revision-yyyymmdd" content="20241009" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                     <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://gitbox.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                   &nbsp;| Last Published: 2024-10-09
              &nbsp;| Version: 3.4.1
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Common</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  
                  
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  
                  
                  
                  
                  
          </ul>
                       <h5>YARN Service</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  
                  
                  
                  
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  
                  
                  
                  
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  
                  
                  
                  
                  
                  
                  
                  
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        
<h1>Apache Hadoop  2.3.0 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, important issues, features, and major improvements.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-9241">HADOOP-9241</a> | <i>Trivial</i> | <b>DU refresh interval is not configurable</b></li>
</ul>
<p>The &#x2018;du&#x2019; (disk usage command from Unix) script refresh monitor is now configurable in the same way as its &#x2018;df&#x2019; counterpart, via the property &#x2018;fs.du.interval&#x2019;, the default of which is 10 minute (in ms).</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-8545">HADOOP-8545</a> | <i>Major</i> | <b>Filesystem Implementation for OpenStack Swift</b></li>
</ul>
Added file system implementation for OpenStack Swift.
There are two implementation: block and native (similar to Amazon S3 integration).
Data locality issue solved by patch in Swift, commit procedure to OpenStack is in progress.

<p>To use implementation add to core-site.xml following:</p>

<div class="source">
<div class="source">
<pre>	&lt;property&gt;
	        &lt;name&gt;fs.swift.impl&lt;/name&gt;
	    	&lt;value&gt;com.mirantis.fs.SwiftFileSystem&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	    	&lt;name&gt;fs.swift.block.impl&lt;/name&gt;
	         &lt;value&gt;com.mirantis.fs.block.SwiftBlockFileSystem&lt;/value&gt;
        &lt;/property&gt;
</pre></div></div>

<p>In MapReduce job specify following configs for OpenStack Keystone authentication:</p>

<div class="source">
<div class="source">
<pre>conf.set(&quot;swift.auth.url&quot;, &quot;http://172.18.66.117:5000/v2.0/tokens&quot;);
conf.set(&quot;swift.tenant&quot;, &quot;superuser&quot;);
conf.set(&quot;swift.username&quot;, &quot;admin1&quot;);
conf.set(&quot;swift.password&quot;, &quot;password&quot;);
conf.setInt(&quot;swift.http.port&quot;, 8080);
conf.setInt(&quot;swift.https.port&quot;, 443);
</pre></div></div>

<p>Additional information specified on github: <a class="externalLink" href="https://github.com/DmitryMezhensky/Hadoop-and-Swift-integration">https://github.com/DmitryMezhensky/Hadoop-and-Swift-integration</a></p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-1176">MAPREDUCE-1176</a> | <i>Major</i> | <b>FixedLengthInputFormat and FixedLengthRecordReader</b></li>
</ul>
<p>Addition of FixedLengthInputFormat and FixedLengthRecordReader in the org.apache.hadoop.mapreduce.lib.input package. These two classes can be used when you need to read data from files containing fixed length (fixed width) records. Such files have no CR/LF (or any combination thereof), no delimiters etc, but each record is a fixed length, and extra data is padded with spaces. The data is one gigantic line within a file. When creating a job that specifies this input format, the job must have the &#x201c;mapreduce.input.fixedlengthinputformat.record.length&#x201d; property set as follows myJobConf.setInt(&#x201c;mapreduce.input.fixedlengthinputformat.record.length&#x201d;,[myFixedRecordLength]);</p>
<p>Please see javadoc for more details.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5502">HDFS-5502</a> | <i>Major</i> | <b>Fix HTTPS support in HsftpFileSystem</b></li>
</ul>
<p>Fix the https support in HsftpFileSystem. With the change the client now verifies the server certificate. In particular, client side will verify the Common Name of the certificate using a strategy specified by the configuration property &#x201c;hadoop.ssl.hostname.verifier&#x201d;.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10047">HADOOP-10047</a> | <i>Major</i> | <b>Add a directbuffer Decompressor API to hadoop</b></li>
</ul>
<p>Direct Bytebuffer decompressors for Zlib (Deflate &amp; Gzip) and Snappy</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-4997">HDFS-4997</a> | <i>Major</i> | <b>libhdfs doesn&#x2019;t return correct error codes in most cases</b></li>
</ul>
<p>libhdfs now returns correct codes in errno. Previously, due to a bug, many functions set errno to 255 instead of the more specific error code.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5536">HDFS-5536</a> | <i>Major</i> | <b>Implement HTTP policy for Namenode and DataNode</b></li>
</ul>
<p>Add new HTTP policy configuration. Users can use &#x201c;dfs.http.policy&#x201d; to control the HTTP endpoints for NameNode and DataNode. Specifically, The following values are supported: - HTTP_ONLY : Service is provided only on http - HTTPS_ONLY : Service is provided only on https - HTTP_AND_HTTPS : Service is provided both on http and https</p>
<p>hadoop.ssl.enabled and dfs.https.enabled are deprecated. When the deprecated configuration properties are still configured, currently http policy is decided based on the following rules: 1. If dfs.http.policy is set to HTTPS_ONLY or HTTP_AND_HTTPS. It picks the specified policy, otherwise it proceeds to 2~4. 2. It picks HTTPS_ONLY if hadoop.ssl.enabled equals to true. 3. It picks HTTP_AND_HTTPS if dfs.https.enable equals to true. 4. It picks HTTP_ONLY for other configurations.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-4983">HDFS-4983</a> | <i>Major</i> | <b>Numeric usernames do not work with WebHDFS FS</b></li>
</ul>
<p>Add a new configuration property &#x201c;dfs.webhdfs.user.provider.user.pattern&#x201d; for specifying user name filters for WebHDFS.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5663">HDFS-5663</a> | <i>Major</i> | <b>make the retry time and interval value configurable in openInfo()</b></li>
</ul>
<p>Makes the retries and time between retries getting the length of the last block on file configurable.  Below are the new configurations.</p>
<p>dfs.client.retry.times.get-last-block-length dfs.client.retry.interval-ms.get-last-block-length</p>
<p>They are set to the 3 and 4000 respectively, these being what was previously hardcoded.</p><hr />
<ul>

<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5704">HDFS-5704</a> | <i>Major</i> | <b>Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK</b></li>
</ul>
<p>Add a new editlog record (OP_ADD_BLOCK) that only records allocation of the new block instead of the entire block list, on every block allocation.</p>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2008-2024
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
