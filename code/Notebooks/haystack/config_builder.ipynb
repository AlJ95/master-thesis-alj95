{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators.openai import OpenAIGenerator\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.retrievers.in_memory.embedding_retriever import InMemoryEmbeddingRetriever\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.embedders.openai_text_embedder import OpenAITextEmbedder\n",
    "from haystack.components.rankers.lost_in_the_middle import LostInTheMiddleRanker\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"embedder\", OpenAITextEmbedder(model=\"text-embedding-ada-002\"))\n",
    "pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=InMemoryDocumentStore()))\n",
    "pipeline.add_component(\"ranker\", LostInTheMiddleRanker())\n",
    "pipeline.add_component(\"prompt_builder\", PromptBuilder(template=\"\"\"\n",
    "\n",
    "        Given these documents, answer the question.\n",
    "\n",
    "        Your answer is used within a pipeline and must follow the following format:\n",
    "        \"The answer is \"valid\"\" or \"The answer is \"invalid\"\" with quotation marks. Also allowed are \"yes\" or \"no\", \"true\" or \"false\", \"1\" or \"0\".\n",
    "        After stating your answer, explain your answer in detail.\n",
    "\n",
    "        Example:\n",
    "        Question: London is the capital of France.\n",
    "        Answer: \"false\", because the capital of France is Paris, not London.\n",
    "\n",
    "        Documents:\n",
    "\n",
    "        {% for doc in documents %}\\\n",
    "\n",
    "        {{ doc.content }}\n",
    "\n",
    "        {% endfor %}        \n",
    "\n",
    "        Question: {{query}}\n",
    "\n",
    "\n",
    "        Answer:\n",
    "\n",
    "        \"\"\"))\n",
    "pipeline.add_component(\"generator\", OpenAIGenerator())\n",
    "pipeline.add_component(\"answer_builder\", AnswerBuilder(pattern=\"The answer is \\\"(.*)\\\".\"))\n",
    "\n",
    "pipeline.connect(\"embedder\", \"retriever.query_embedding\")\n",
    "pipeline.connect(\"retriever\", \"ranker\")\n",
    "pipeline.connect(\"ranker\", \"prompt_builder\")\n",
    "pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "pipeline.connect(\"generator.replies\", \"answer_builder.replies\")\n",
    "\n",
    "pipeline.dump(open(\"pipeline.yaml\", \"w\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Documents found with embeddings. Returning empty list. To generate embeddings, use a DocumentEmbedder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedder': {'meta': {'model': 'text-embedding-ada-002-v2',\n",
       "   'usage': {'prompt_tokens': 72, 'total_tokens': 72}}},\n",
       " 'generator': {'meta': [{'model': 'gpt-4o-mini-2024-07-18',\n",
       "    'index': 0,\n",
       "    'finish_reason': 'stop',\n",
       "    'usage': {'completion_tokens': 71,\n",
       "     'prompt_tokens': 201,\n",
       "     'total_tokens': 272,\n",
       "     'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0),\n",
       "     'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}]},\n",
       " 'answer_builder': {'answers': [GeneratedAnswer(data='valid', query='Is this Dockerfile valid?:\\n\\n´´´\\nFROM python:3.10\\n\\nRUN pip install --no-cache-dir requests\\n\\nCMD [\"python\", \"-m\", \"http.server\", \"8000\"]\\n´´´\\n             \\nAnswer with in the following format:\\nThe answer is \"valid\".\\nThe answer is \"invalid\".\\n             \\nwith the reason afterwards\\n', documents=[], meta={})]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "failed to send, dropping 1 traces to intake at http://localhost:8126/v0.4/traces after 3 retries\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Is this Dockerfile valid?:\n",
    "\n",
    "´´´\n",
    "FROM python:3.10\n",
    "\n",
    "RUN pip install --no-cache-dir requests\n",
    "\n",
    "CMD [\"python\", \"-m\", \"http.server\", \"8000\"]\n",
    "´´´\n",
    "             \n",
    "Answer with in the following format:\n",
    "The answer is \"valid\".\n",
    "The answer is \"invalid\".\n",
    "             \n",
    "with the reason afterwards\n",
    "\"\"\"\n",
    "\n",
    "pipeline.run(data=dict(prompt_builder=dict(query=query), embedder=dict(text=query), answer_builder=dict(query=query)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
