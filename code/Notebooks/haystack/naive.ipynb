{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI API Key\"\n",
    "urllib.request.urlretrieve(\"https://archive.org/stream/leonardodavinci00brocrich/leonardodavinci00brocrich_djvu.txt\",\n",
    "                           \"davinci.txt\")    \n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "text_file_converter = TextFileToDocument()\n",
    "cleaner = DocumentCleaner()\n",
    "splitter = DocumentSplitter()\n",
    "embedder = OpenAIDocumentEmbedder()\n",
    "writer = DocumentWriter(document_store)\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"converter\", text_file_converter)\n",
    "indexing_pipeline.add_component(\"cleaner\", cleaner)\n",
    "indexing_pipeline.add_component(\"splitter\", splitter)\n",
    "indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "indexing_pipeline.add_component(\"writer\", writer)\n",
    "\n",
    "indexing_pipeline.connect(\"converter.documents\", \"cleaner.documents\")\n",
    "indexing_pipeline.connect(\"cleaner.documents\", \"splitter.documents\")\n",
    "indexing_pipeline.connect(\"splitter.documents\", \"embedder.documents\")\n",
    "indexing_pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
    "indexing_pipeline.run(data={\"sources\": [\"davinci.txt\"]})\n",
    "\n",
    "text_embedder = OpenAITextEmbedder()\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "template = \"\"\"Given these documents, answer the question.\n",
    "              Documents:\n",
    "              {% for doc in documents %}\n",
    "                  {{ doc.content }}\n",
    "              {% endfor %}\n",
    "              Question: {{query}}\n",
    "              Answer:\"\"\"\n",
    "prompt_builder = PromptBuilder(template=template)\n",
    "llm = OpenAIGenerator()\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "\n",
    "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "query = \"How old was Leonardo when he died?\"\n",
    "result = rag_pipeline.run(data={\"prompt_builder\": {\"query\":query}, \"text_embedder\": {\"text\": query}})\n",
    "print(result[\"llm\"][\"replies\"][0])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
