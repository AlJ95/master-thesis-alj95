@misc{PLACEHOLDER, journal={PLACEHOLDER JOURNAL}, author={PLACEHOLDER | Needs to be cited fact}, year={????}, title={ToDo | CITE | ae oe ue ?}, } 

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017, revised in 2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{Wolf.09.10.2019,
 abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \url{https://github.com/huggingface/transformers}.},
 author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and {Le Scao}, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
 date = {09.10.2019},
 year = {2019},
 title = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
 url = {http://arxiv.org/pdf/1910.03771},
 file = {Wolf, Debut et al 09102019 - HuggingFace's Transformers:Attachments/Wolf, Debut et al 09102019 - HuggingFace's Transformers.pdf:application/pdf;Wolf, Debut et al. 09.10.2019 - HuggingFace's Transformers:Attachments/Wolf, Debut et al. 09.10.2019 - HuggingFace's Transformers.pdf:application/pdf}
}

% This file was created with Citavi 6.18.0.1

@misc{Hou.8212023,
 abstract = {Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We select and analyze 395 research papers from January 2017 to January 2024 to answer four key research questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, preprocessing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and flagging promising areas for future study. Our artifacts are publicly available at https://github.com/xinyi-hou/LLM4SE{\_}SLR.},
 author = {Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and {Lo David} and Grundy, John and Wang, Haoyu},
 date = {8/21/2023},
 year = {2023},
 title = {Large Language Models for Software Engineering: A Systematic Literature Review},
 url = {http://arxiv.org/pdf/2308.10620v6},
 keywords = {Generation Task;LLM4SE},
 file = {2308.10620v6:Attachments/2308.10620v6.pdf:application/pdf}
}


@inproceedings{Yin.2024,
 author = {Yin, Junqi and Bose, Avishek and Cong, Guojing and Lyngaas, Isaac and Anthony, Quentin},
 title = {Comparative Study of Large Language Model Architectures on Frontier},
 pages = {556--569},
 publisher = {IEEE},
 isbn = {979-8-3503-8711-7},
 editor = {Chard, Kyle and Li, Zhuozhao},
 booktitle = {2024 IEEE International Parallel and Distributed Processing Symposium},
 year = {2024},
 address = {Piscataway, NJ},
 doi = {10.1109/IPDPS57955.2024.00056},
 file = {Yin, Bose et al. 5 27 2024 - 5 31 2024 - Comparative Study of Large Language:Attachments/Yin, Bose et al. 5 27 2024 - 5 31 2024 - Comparative Study of Large Language.pdf:application/pdf}
}

@article{ACKLEY.1985,
 author = {ACKLEY, D. and HINTON, G. and SEJNOWSKI, T.},
 year = {1985},
 title = {A learning algorithm for boltzmann machines},
 pages = {147--169},
 volume = {9},
 number = {1},
 issn = {03640213},
 journal = {Cognitive Science},
 doi = {10.1016/S0364-0213(85)80012-4},
 file = {ACKLEY, HINTON et al. 1985 - A learning algorithm for boltzmann:Attachments/ACKLEY, HINTON et al. 1985 - A learning algorithm for boltzmann.pdf:application/pdf}
}

@misc{Fan.13.05.2018,
 abstract = {We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.},
 author = {Fan, Angela and Lewis, Mike and Dauphin, Yann},
 date = {13.05.2018},
 year = {2018},
 title = {Hierarchical Neural Story Generation},
 url = {http://arxiv.org/pdf/1805.04833},
 file = {Fan, Lewis et al. 13.05.2018 - Hierarchical Neural Story Generation:Attachments/Fan, Lewis et al. 13.05.2018 - Hierarchical Neural Story Generation.pdf:application/pdf}
}

@misc{Holtzman.22.04.2019,
 abstract = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive.  In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
 author = {Holtzman, Ari and Buys, Jan and {Du Li} and Forbes, Maxwell and Choi, Yejin},
 date = {22.04.2019},
 year = {2019},
 title = {The Curious Case of Neural Text Degeneration},
 url = {http://arxiv.org/pdf/1904.09751},
 file = {Holtzman, Buys et al. 22.04.2019 - The Curious Case of Neural:Attachments/Holtzman, Buys et al. 22.04.2019 - The Curious Case of Neural.pdf:application/pdf}
}

@misc{OpenAI_2022, url={https://openai.com/index/chatgpt}, journal={Introducing chatgpt}, author={OpenAI}, year={2022}, month={Nov}} 

@misc{Anthropic_2023, title={Introducing claude}, url={https://www.anthropic.com/news/introducing-claude}, journal={Anthropic}, author={Anthropic}, year={2023}, month={Mar}} 

@misc{DeepL_SE, title={Deepl übersetzer: Der Präziseste übersetzer der welt}, url={https://www.deepl.com/de/}, journal={DeepL Übersetzer: Der präziseste Übersetzer der Welt}, author={DeepL}, year={2017}} 

@misc{Friedman_2022, title={Introducing github copilot: Your AI pair programmer}, url={https://github.blog/news-insights/product-news/introducing-github-copilot-ai-pair-programmer/}, journal={The GitHub Blog}, author={Friedman, Nat}, year={2022}, month={Feb}} 

% This file was created with Citavi 6.19.2.1

@misc{Zhang.03.09.2023,
 abstract = {While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.},
 author = {Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and Wang, Longyue and Luu, Anh Tuan and Bi, Wei and Shi, Freda and Shi, Shuming},
 date = {03.09.2023},
 year = {2023},
 title = {Siren's Song in the AI Ocean: A Survey on Hallucination in Large  Language Models},
 url = {http://arxiv.org/pdf/2309.01219},
 keywords = {Hallucinations;LLMs},
 file = {Zhang, Li et al. 03.09.2023 - Siren's Song in the AI:Attachments/Zhang, Li et al. 03.09.2023 - Siren's Song in the AI.pdf:application/pdf}
}

@misc{Simon.10112024,
 abstract = {Retrieval-augmented generation (RAG) is an umbrella of different components, design decisions, and domain-specific adaptations to enhance the capabilities of large language models and counter their limitations regarding hallucination and outdated and missing knowledge. Since it is unclear which design decisions lead to a satisfactory performance, developing RAG systems is often experimental and needs to follow a systematic and sound methodology to gain sound and reliable results. However, there is currently no generally accepted methodology for RAG evaluation despite a growing interest in this technology. In this paper, we propose a first blueprint of a methodology for a sound and reliable evaluation of RAG systems and demonstrate its applicability on a real-world software engineering research task: the validation of configuration dependencies across software technologies. In summary, we make two novel contributions: (i) A novel, reusable methodological design for evaluating RAG systems, including a demonstration that represents a guideline, and (ii) a RAG system, which has been developed following this methodology, that achieves the highest accuracy in the field of dependency validation. For the blueprint's demonstration, the key insights are the crucial role of choosing appropriate baselines and metrics, the necessity for systematic RAG refinements derived from qualitative failure analysis, as well as the reporting practices of key design decision to foster replication and evaluation.},
 author = {Simon, Sebastian and Mailach, Alina and Dorn, Johannes and Siegmund, Norbert},
 date = {10/11/2024},
 year = {2024},
 title = {A Methodology for Evaluating RAG Systems: A Case Study On Configuration Dependency Validation},
 url = {http://arxiv.org/pdf/2410.08801v1},
 keywords = {Benchmarking;evaluation;Replicable;Validity},
 file = {2410.08801v1:Attachments/2410.08801v1.pdf:application/pdf}
}

@misc{Yu.2024,
 abstract = {Retrieval-Augmented Generation (RAG) has recently gained traction in natural language processing. Numerous studies and real-world applications are leveraging its ability to enhance generative models through external information retrieval. Evaluating these RAG systems, however, poses unique challenges due to their hybrid structure and reliance on dynamic knowledge sources. To better understand these challenges, we conduct A Unified Evaluation Process of RAG (Auepora) and aim to provide a comprehensive overview of the evaluation and benchmarks of RAG systems. Specifically, we examine and compare several quantifiable metrics of the Retrieval and Generation components, such as relevance, accuracy, and faithfulness, within the current RAG benchmarks, encompassing the possible output and ground truth pairs. We then analyze the various datasets and metrics, discuss the limitations of current benchmarks, and suggest potential directions to advance the field of RAG benchmarks.},
 author = {Yu, Hao and Gan, Aoran and Zhang, Kai and Tong, Shiwei and Liu, Qi and Liu, Zhaofeng},
 year = {2024},
 title = {Evaluation of Retrieval-Augmented Generation: A Survey},
 keywords = {Auepora;Benchmarking;evaluation;Metrics;Retrieval-Augmented Generation},
 file = {Yu, Gan et al. 2024 - Evaluation of Retrieval-Augmented Generation:Attachments/Yu, Gan et al. 2024 - Evaluation of Retrieval-Augmented Generation.pdf:application/pdf}
}

% This file was created with Citavi 6.19.2.1

@inproceedings{Salemi.2024,
 author = {Salemi, Alireza and Zamani, Hamed},
 title = {Evaluating Retrieval Quality in Retrieval-Augmented Generation},
 keywords = {Document-level Retrieval Evaluation;eRAG;Retrieval Evaluation;Retrieval Quality;Retrieval-Augmented Generation},
 pages = {2395--2400},
 publisher = {ACM},
 booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 year = {2024},
 address = {New York, NY, USA},
 doi = {10.1145/3626772.3657957},
 file = {Salemi, Zamani 2024 - Evaluating Retrieval Quality in Retrieval-Augmented:Attachments/Salemi, Zamani 2024 - Evaluating Retrieval Quality in Retrieval-Augmented.pdf:application/pdf}
}







@misc{Kandpal.15.11.2022,
 abstract = {The Internet contains a wealth of knowledge -- from the birthdays of historical figures to tutorials on how to code -- all of which may be learned by language models. However, while certain pieces of information are ubiquitous on the web, others appear extremely rarely. In this paper, we study the relationship between the knowledge memorized by large language models and the information in pre-training datasets scraped from the web. In particular, we show that a language model's ability to answer a fact-based question relates to how many documents associated with that question were seen during pre-training. We identify these relevant documents by entity linking pre-training datasets and counting documents that contain the same entities as a given question-answer pair. Our results demonstrate strong correlational and causal relationships between accuracy and relevant document count for numerous question answering datasets (e.g., TriviaQA), pre-training corpora (e.g., ROOTS), and model sizes (e.g., 176B parameters). Moreover, while larger models are better at learning long-tail knowledge, we estimate that today's models must be scaled by many orders of magnitude to reach competitive QA performance on questions with little support in the pre-training data. Finally, we show that retrieval-augmentation can reduce the dependence on relevant pre-training information, presenting a promising approach for capturing the long-tail.},
 author = {Kandpal, Nikhil and Deng, Haikang and Roberts, Adam and Wallace, Eric and Raffel, Colin},
 date = {15.11.2022},
 year = {2022},
 title = {Large Language Models Struggle to Learn Long-Tail Knowledge},
 url = {http://arxiv.org/pdf/2211.08411},
 keywords = {Hallucinations;LLMs;Long-Tail Information},
 file = {Kandpal, Deng et al. 15.11.2022 - Large Language Models Struggle:Attachments/Kandpal, Deng et al. 15.11.2022 - Large Language Models Struggle.pdf:application/pdf}
}


@inproceedings{Rashkin.,
 author = {Rashkin, Hannah and Reitter, David and Tomar, Gaurav Singh and Das, Dipanjan},
 title = {Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features},
 keywords = {Hallucinations;LLMs},
 pages = {704--718},
 publisher = {{Association for Computational Linguistics}},
 editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
 booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
 address = {Stroudsburg, PA, USA},
 doi = {10.18653/v1/2021.acl-long.58},
 year = {2021},
 file = {Rashkin, Reitter et al. - Increasing Faithfulness in Knowledge-Grounded Dialogue:Attachments/Rashkin, Reitter et al. - Increasing Faithfulness in Knowledge-Grounded Dialogue.pdf:application/pdf}
}


% RAG Frameworks
@misc{Liu_LlamaIndex_2022,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = {11},
title = {{LlamaIndex}},
howpublished = {\url{https://github.com/jerryjliu/llama_index}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}

@misc{Chase_LangChain_2022,
author = {Chase, Harrison},
month = oct,
title = {{LangChain}},
url = {https://github.com/langchain-ai/langchain},
howpublished = {\url{https://github.com/langchain-ai/langchain}},
year = {2022}
}


@misc{AutoRAG,
author = {Kim, Jeffrey and Kim, Bobb},
month = feb,
title = {{AutoRAG}},
url = {https://github.com/Marker-Inc-Korea/AutoRAG},
howpublished = {\url{https://github.com/Marker-Inc-Korea/AutoRAG}},
year = {2024}
}


@inproceedings{zhang-etal-2024-raglab,
    title = "{RAGLAB}: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation",
    author = "Zhang, Xuanwang and
      Song, Yunze and
      Wang, Yidong and
      Tang, Shuyun and
      others",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2024",
    publisher = "Association for Computational Linguistics",
}

@software{Izsak_fastRAG_Efficient_Retrieval_2023,
author = {Izsak, Peter and Berchansky, Moshe and Fleischer, Daniel and Laperdon, Ronen},
license = {Apache-2.0},
month = feb,
title = {{fastRAG: Efficient Retrieval Augmentation and Generation Framework}},
howpublished = {\url{https://github.com/IntelLabs/fastrag}},
url = {https://github.com/IntelLabs/fastrag},
version = {1.0},
year = {2023}
}

@software{Pietsch_Haystack_the_end-to-end_2019,
author = {Pietsch, Malte and Möller, Timo and Kostic, Bogdan and Risch, Julian and Pippi, Massimiliano and Jobanputra, Mayank and Zanzottera, Sara and Cerza, Silvano and Blagojevic, Vladimir and Stadelmann, Thomas and Soni, Tanay and Lee, Sebastian},
month = nov,
title = {{Haystack: the end-to-end NLP framework for pragmatic builders}},
howpublished = {\url{https://github.com/deepset-ai/haystack}},
url = {https://github.com/deepset-ai/haystack},
year = {2019}
}

@misc{ralle,
      title={RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models}, 
      author={Yasuto Hoshi and Daisuke Miyashita and Youyang Ng and Kento Tatsuno and Yasuhiro Morioka and Osamu Torii and Jun Deguchi},
      url={https://arxiv.org/abs/2308.10633},
      year={2023},
      eprint={2308.10633},
      howpublished = {\url{https://arxiv.org/abs/2308.10633}},
      publisher={arXiv}
}

@article{FlashRAG,
    author={Jiajie Jin and
            Yutao Zhu and
            Xinyu Yang and
            Chenghao Zhang and
            Zhicheng Dou},
    title={FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research},
    journal={CoRR},
    volume={abs/2405.13576},
    year={2024},
    url={https://arxiv.org/abs/2405.13576},
    howpublished = {\url{https://arxiv.org/abs/2405.13576}},
    eprinttype={arXiv},
    eprint={2405.13576}
}

% Text Retrieval
% This file was created with Citavi 6.19.2.1

@misc{Zhao.29.02.2024,
 abstract = {Advancements in model algorithms, the growth of foundational models, and access to high-quality datasets have propelled the evolution of Artificial Intelligence Generated Content (AIGC). Despite its notable successes, AIGC still faces hurdles such as updating knowledge, handling long-tail data, mitigating data leakage, and managing high training and inference costs. Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges. In particular, RAG introduces the information retrieval process, which enhances the generation process by retrieving relevant objects from available data stores, leading to higher accuracy and better robustness. In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios. We first classify RAG foundations according to how the retriever augments the generator, distilling the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems. Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research. Github: https://github.com/PKU-DAIR/RAG-Survey.},
 author = {Zhao, Penghao and Zhang, Hailin and Yu, Qinhan and Wang, Zhengren and Geng, Yunteng and Fu, Fangcheng and Yang, Ling and Zhang, Wentao and Jiang, Jie and Cui, Bin},
 date = {29.02.2024},
 year = {2024},
 title = {Retrieval-Augmented Generation for AI-Generated Content: A Survey},
 url = {http://arxiv.org/pdf/2402.19473},
 file = {Zhao, Zhang et al. 29.02.2024 - Retrieval-Augmented Generation for AI-Generated Content:Attachments/Zhao, Zhang et al. 29.02.2024 - Retrieval-Augmented Generation for AI-Generated Content.pdf:application/pdf}
}


@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}


@misc{karpukhin2020densepassageretrievalopendomain,
      title={Dense Passage Retrieval for Open-Domain Question Answering}, 
      author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
      year={2020},
      eprint={2004.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.04906}, 
}

% This file was created with Citavi 7.0.4.0

@book{Manning.2009,
 author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
 year = {2009},
 title = {Introduction to information retrieval},
 address = {Cambridge},
 edition = {Reprinted.},
 publisher = {{Cambridge Univ. Press}},
 isbn = {9780521865715},
 doi = {10.1017/CBO9780511809071},
 file = {Manning, Raghavan et al. 2009 - Introduction to information retrieval:Attachments/Manning, Raghavan et al. 2009 - Introduction to information retrieval.pdf:application/pdf}
}


% This file was created with Citavi 7.0.4.0

@misc{Gao.18.12.2023,
 abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
 author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
 date = {18.12.2023},
 year = {2023},
 title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
 url = {http://arxiv.org/pdf/2312.10997},
 keywords = {Advanced RAG;answer faithfulness;augmentation;Context Relevance;evaluation;framework;Large Language Models;Modular RAG;Naive RAG;Retrieval-Augmented Generation},
 file = {Gao, Xiong et al. 18.12.2023 - Retrieval-Augmented Generation for Large Language:Attachments/Gao, Xiong et al. 18.12.2023 - Retrieval-Augmented Generation for Large Language.pdf:application/pdf}
}


% This file was created with Citavi 7.0.4.0

@misc{Huang.2023,
 abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.},
 author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
 date = {2024},
 year = {2024},
 title = {A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
 url = {http://arxiv.org/pdf/2311.05232},
 doi = {10.1145/3703155},
 file = {Huang, Yu et al. 2023 - A Survey on Hallucination:Attachments/Huang, Yu et al. 2023 - A Survey on Hallucination.pdf:application/pdf}
}


% This file was created with Citavi 7.0.4.0

@article{Chen.2024,
 abstract = {Retrieval-Augmented Generation (RAG) ist eine vielversprechende Methode, um Halluzinationen von gro{\ss}en Sprachmodellen (LLMs) zu minimieren. Allerdings fehlt es an umfassender Evaluierung, wie sich RAG auf unterschiedliche LLMs auswirkt, was es schwierig macht, Engp{\"a}sse in der Leistungsf{\"a}higkeit von RAG zu identifizieren. In dieser Arbeit untersuchen wir systematisch den Einfluss von RAG auf LLMs und analysieren deren Leistung in vier wesentlichen F{\"a}higkeiten: Noise Robustness (St{\"o}rungsrobustheit), Negative Rejection (Ablehnung falscher Informationen), Information Integration (Informationsintegration) und Counterfactual Robustness (Robustheit gegen{\"u}ber falschen Informationen). Hierf{\"u}r haben wir den Retrieval-Augmented Generation Benchmark (RGB) erstellt und sechs repr{\"a}sentative LLMs in Englisch und Chinesisch bewertet. Die Ergebnisse zeigen, dass, obwohl RAG die Genauigkeit von Antworten verbessert, die Modelle immer noch erhebliche Schw{\"a}chen in diesen Bereichen aufweisen.},
 author = {Chen, Jiawei and Lin, Hongyu and Han, Xianpei and {Le Sun}},
 year = {2024},
 title = {Benchmarking Large Language Models in Retrieval-Augmented Generation},
 keywords = {Benchmarking;Counterfactual Robustness;Information Integration;Large Language Models;Negative Rejection;Noise Robustness;Retrieval-Augmented Generation},
 pages = {17754--17762},
 volume = {38},
 number = {16},
 issn = {2159-5399},
 journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
 doi = {10.1609/aaai.v38i16.29728},
 file = {Chen, Lin et al. 2024 - Benchmarking Large Language Models:Attachments/Chen, Lin et al. 2024 - Benchmarking Large Language Models.pdf:application/pdf}
}

@inproceedings{Shuster.,
 author = {Shuster, Kurt and Poff, Spencer and Chen, Moya and Kiela, Douwe and Weston, Jason},
 title = {Retrieval Augmentation Reduces Hallucination in Conversation},
 pages = {3784--3803},
 publisher = {{Association for Computational Linguistics}},
 editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
 booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
 address = {Stroudsburg, PA, USA},
 year = {2021},
 doi = {10.18653/v1/2021.findings-emnlp.320},
 file = {Shuster, Poff et al. - Retrieval Augmentation Reduces Hallucination:Attachments/Shuster, Poff et al. - Retrieval Augmentation Reduces Hallucination.pdf:application/pdf}
}


