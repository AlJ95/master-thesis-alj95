\section{Large Language Models}

Die Frage hier: Ein grobes Kapitel zu LLMs oder gr\"obere Unterkapitel zum Aufarbeiten ab Neural Networks (Masterstudenten sollen es lesen k\"onnen. Alle sollten NNs kennen, aber nicht alle habe Kenntnisse in der Transformer Architecture -> Ist das \"uberhaupt relevant\ss)

Am Ende geht es ja darum, dass Studenten verstehen, wie die Eigenschaften solcher Systeme sind, es ist keine Theoriestunde zur tiefen Verst\"andnis der Themen sondern soll die Selbsterkl\"arbarkeit der Masterarbeit verst\"arken (self-contained)

\subsection{Recurrent Neural Networks}
Sicher nicht ben\"otigt
\subsection{Sequence to Sequence Models}
Sicher nicht ben\"otigt
\subsection{Transformer Architecture}
Unsicher

Encoder 

Decoder

\section{Information Retrieval}

\subsection{Sparse Retrieval}
Hier sollte grob erkl\"art werden was der BM25 Algorithmus ist. Vielleciht auch andere, die ich anbiete\ss

\subsection{Dense Retrieval}
Hier sollte auf Embeddings eingegangen werden und wie dessen Eigenschaften sind. 


