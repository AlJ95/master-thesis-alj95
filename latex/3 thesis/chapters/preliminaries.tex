\section{Large Language Models}

Die Frage hier: Ein grobes Kapitel zu LLMs oder gröbere Unterkapitel zum Aufarbeiten ab Neural Networks (Masterstudenten sollen es lesen können. Alle sollten NNs kennen, aber nicht alle habe Kenntnisse in der Transformer Architecture -> Ist das überhaupt relevant?)

Am Ende geht es ja darum, dass Studenten verstehen, wie die Eigenschaften solcher Systeme sind, es ist keine Theoriestunde zur tiefen Verständnis der Themen sondern soll die Selbsterklärbarkeit der Masterarbeit verstärken (self-contained)

\subsection{Recurrent Neural Networks}
Sicher nicht benötigt
\subsection{Sequence to Sequence Models}
Sicher nicht benötigt
\subsection{Transformer Architecture}
Unsicher

Encoder 

Decoder

\section{Information Retrieval}

\subsection{Sparse Retrieval}
Hier sollte grob erklärt werden was der BM25 Algorithmus ist. Vielleciht auch andere, die ich anbiete?

\subsection{Dense Retrieval}
Hier sollte auf Embeddings eingegangen werden und wie dessen Eigenschaften sind. 


